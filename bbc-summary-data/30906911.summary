[SN]URL[SN]
http://web.archive.org/web/20170201093231/http://www.bbc.com/newsbeat/30906911

[SN]TITLE[SN]
Ex Machina and what the robot apocalypse will look like

[SN]FIRST-SENTENCE[SN]
Ex Machina is your standard film script of boy meets girl.

[SN]RESTBODY[SN]
Except that this girl is a robot: a robot girlfriend programmed by a sociopathic billionaire.
And she is a robot who may just want a mind of her own - with a master who won't relinquish control.
The film is out in UK cinemas now.
Written by Alex Garland, author of The Beach, it's a thriller starring Domhnall Gleeson as computer programmer Caleb, Alicia Vikander as robot Ava and Oscar Isaac as Nathan, the billionaire.
It explores some of our deepest fears about artificial intelligence (AI).
Ex Machina's robot, Ava, is not the only type of AI we should find unsettling, Garland told Newsbeat.
He said: "AI that is in control of stock markets, in control of healthcare systems, factories, maybe military drones. It is different from Ava but you can be scared of that."
These are the type of AI that led inventor and entrepreneur Elon Musk to declare AI as "the most serious threat to the survival of the human race".
The SpaceX boss has donated $10m (Â£6.6m) to keep AI friendly.
Dr Stuart Armstrong is a member of a research centre which looks into the big questions surrounding AI - the Future of Humanity - at Oxford University.
He is also an adviser to the Lifeboat Foundation, which is tasked with a small matter: safeguarding humanity.
He told Newsbeat about a future world which he says is far more likely to happen than anything shown in Ex Machina.
It is potentially far more terrifying, he reckons.
"AI could outsmart us technologically, it could come up with designs of things far beyond what we could come up with and then build them.
"It could outsmart us on the internet; say hack into every single computer in the world and copy themselves into it.
"It could outsmart us socially which is a particularly scary avenue.
"Maybe humans' social skills are not nearly as special or uncrackable as we like to think. It could seduce us.
"It could have super economic skills.
"It could guess the stock market better and accumulate quantities of cash.
"It doesn't need to have all these skills.
"If you have a general intelligence in one area it is often transferable to other areas.
"If you can accumulate huge amounts of money then you can buy lots of hackers or buy lots of computing power or technological research.
"Similarly if you have technological research you can sell this and accumulate financial resources."
Meanwhile, he says films portraying AI in human terms, particularly portrayals of AI like the Terminator, are "ridiculous".
He explains: "If you want to build a mechanical army to destroy the world, the human frame is probably one of the worst designs that you could go for. I would go for mosquito-sized drones with legs or something like that.
"Every single AI in movies I've ever seen is a human mind with some minor modification. They seem to be emotionally repressed humans. That's the model."
Much of what we might expect AI to be like will be beyond human experience, argues Armstrong.
"It is very possible that we will end up with AI that have no concept of personal identity or nothing that we could recognise as human. Humans are absolutely tiny in the pool of possible minds.
"AIs may be without personal names, of the concept of peer group, of status maybe. They may have different kinds of emotions.
"Emotions that we have no idea or relation to."
He said when people think of the possible risk of AIs to the future of the world "they think of slave AIs and then imagine they might revolt. They think of human-like minds and with human-like reactions to being enslaved".
However, he sees the risk to humanity originating elsewhere.
"The risk is not that these minds will react in this way, the risk is that these super-intelligent minds may have goals that are incompatible with ours, so they extinguish the human race along the way while doing something else, something that might be profoundly uninteresting."
But before you start worrying about how smart your smartphone really is, experts stress that it is hard to predict the future. There are so many variables.
Plus as anyone who has had their car break down, or broadband fail, technology can sometimes be pretty crummy.
Writer Alex Garland's worry is more immediate.
"At the moment in terms of really bad things happening in the world, it is humans who are doing all the running.
"We manage to do the bad stuff pretty well all on our own. We should be looking harder at us. We're doing plenty of bad things without looking at AIs."
Follow @BBCNewsbeat on Twitter, BBCNewsbeat on Instagram and Radio1Newsbeat on YouTube
