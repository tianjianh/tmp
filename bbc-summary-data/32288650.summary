[SN]URL[SN]
http://web.archive.org/web/20150414074235/http://www.bbc.com/news/technology-32288650

[SN]TITLE[SN]
Charity steps up removal of child sex abuse images

[SN]FIRST-SENTENCE[SN]
A child abuse watchdog has said it helped identify and remove more than double the number of sexually explicit web pages depicting youngsters in 2014 than in the previous year.

[SN]RESTBODY[SN]
The UK-based Internet Watch Foundation (IWF) said it assisted in the removal of 31,266 pages last year, compared with 13,182 in 2013.
It said in many cases, each address contained more than one photo or video.
The figures do not necessarily indicate that illegal activity is increasing.
Instead, they may simply reflect that the charity recently began taking a proactive approach, seeking out child abuse imagery rather than just acting on others' reports.
It was able to do this after the UK's four biggest internet service providers committed an extra Â£1m over four years to fund its efforts.
If the material is hosted overseas, the organisation notifies local authorities and then chases up complaints until the material is removed.
"Our ability to actively seek out child sexual abuse imagery created a significant step-change in the effectiveness of the IWF," said chief executive Susie Hargreaves.
The body's annual report says:
The IWF said image-hosting platforms that create a specific web address link when a file is uploaded were the most common type of misused service it had encountered, accounting for about 63% of the offending pages detected.
Such systems typically create what appears to be a random string of numbers and digits as the address, making it harder to trace those sharing extreme material.
One expert suggested this might have contributed to their appeal.
"The paedophiles are looking for ways to make it more difficult for law enforcement to detect them sharing child abuse imagery," said Prof Alan Woodward, who advises Europol on the issue.
"There is a lot of research being done on automatically detecting the images themselves and what keywords to look for in related text.
"But if the paedophiles are sharing what is effectively a signpost - written in code that is in no way related to the nature of material linked to online - then there is much less chance of identifying either those sharing such extreme material or where it is located, in order that it can be removed."
The web has any number of photo-sharing, or "image hosting" sites. They are legal, mostly free and easy to use.
Register, log on, upload and you have your own private collection of images. Only people you select can view them and only once you've sent them a link.  No one else will know what is in your collection.
The link is just a line of code that reveals nothing. And that is where the problem lies. Paedophiles are becoming increasingly aware that known images of abuse can be tracked and traced if shared conventionally: each image has a unique hash value that can trigger red flags for both email providers and law enforcement.
A line of code or URL directing a user to a private collection on an "image hosting" site is anonymous and triggers no alerts.
The IWF figures seem to back up the theory that paedophiles are increasingly turning to these sites. In 2013 analysts found 5,594 such URLs - a figure that had risen to 19,710 by the following year.
Indeed, that accounts for almost two thirds of all links to obscene material identified by the IWF.  Criminals are in effect hiding in plain view on entirely legitimate websites.
