[SN]URL[SN]
http://web.archive.org/web/20170609033514/http://www.bbc.com/news/technology-40190440

[SN]TITLE[SN]
Something must be done...but what?

[SN]FIRST-SENTENCE[SN]
In the days since the London Bridge attack, the pressure on internet companies has been building. They have been told they must take action in two areas - preventing the spread of extremist content, and ending the provision of a safe space for terrorists.

[SN]RESTBODY[SN]
But when I talked to representatives of the major firms they were confused. "We're told 'something must be done,'" one executive told me. "But it's not clear what that "something" is."
That said, the companies are more clear about what is being asked of them when it comes to the first demand - that they take down more of the material that could incite people to commit terrorist acts.
Of course, they all insist that they are already very active on this front - though the politicians will feel that it is only thanks to their pressure that the companies have begun to devote serious resources to this effort.
What they fear now is that the government may look with interest at what is happening in Germany, where a draft law is under discussion which could see companies facing stiff fines if they fail to take down hate speech swiftly.
That is proving very controversial there, with claims that it could give the tech giants too much power to determine what can be said on the internet.
And they are adamant that they should not be given that responsibility in the UK. "It's up to legislators to determine what is legal," one executive told me."If the government hands that power to tech firms that's a problem - the rule of law is better than the whim of tech firms."
The companies point out that determining what is extremist content and should be removed, is not simple. One example -  videos by the American radical preacher Ahmad Musa Jibril which one of the London attackers is said to have viewed.
YouTube says that they don't break its rules because they are religious sermons containing no call to violence, so they remain online, What's more, the US authorities have allowed this man to remain at liberty, so it is not clear on what basis his videos could be removed from a global platform.
The Sun newspaper says today that if YouTube, Facebook and Twitter fail to remove this kind of content, the Prime Minister should consider the nuclear option - "ordering our internet service providers to shut down these vast sites until they are purged."
Censoring the internet in that way would be an extraordinary step - though the Conservative manifesto does have this intriguing passage: 'Some people say that it is not for government to regulate when it comes to technology and the internet. We disagree.'
But the internet firms still seem confident they can work with the government on regulating content. What they are really concerned about is what the politicians are thinking about end-to-end encryption - the "safe space" given to terrorists by messaging systems like WhatsApp and Apple's iMessage, where the companies themselves cannot decode what is said.
Ministers have said two things that seem contradictory - that there cannot be messaging systems where in extremis the law enforcement agencies cannot get access to what is being said, and that they do not want to weaken encryption.
"It's very difficult to know what the government wants to do," said one executive whose company could be in the firing line over this issue.
The technology industry is largely united in the belief that you cannot put the encryption genie back into the bottle - and insistent that backdoors into their systems would inevitably be exploited by criminals.
They point to the recent Wannacry ransomware attacks, carried out using hacking tools stolen from America's National Security Agency, as evidence of what happens when governments hoard software vulnerabilities.
But one former Downing Street official has pushed back against the idea that nothing can be done about these safe spaces.
Rohan Silva, who worked as a digital policy advisor to David Cameron, says the tech firms need to address this issue at a far more senior level. And writing in the London Evening Standard he says there are ideas for confronting the encryption problem:
"The Home Office has developed sensible proposals that require a judge to give permission before real-time communications can be monitored â€” ensuring that suspected terrorists can be stopped before it's too late, while also protecting against the mass surveillance that the public is worried about."
What isn't clear however is how - even with a judge's permission - the likes of WhatsApp could enable the real-time monitoring of messages without effectively disabling end-to-end encryption.
Now we may as a country decide that this is desirable, but there is then the danger that the terrorists will simply use other encrypted services outside the UK's jurisdiction.
But the tech firms report that the response of ministers to quibbles of this nature often amounts to "you've got thousands of boffins, if you're so clever why can't you fix this?"  Having been subjected to endless hype about the role technology can play in transforming the world, the politicians are frustrated that it can't seem to help here.
The relationship between the tech giants and the politicians is looking increasingly dysfunctional, with a lack of understanding on both sides.  For all our sakes, they need to start speaking each other's language.
